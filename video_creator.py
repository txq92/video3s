import os
import uuid
import random
from google import genai
from google.genai import types
from moviepy import (
    VideoFileClip, AudioFileClip, ImageClip, ColorClip, 
    CompositeVideoClip, concatenate_videoclips
)
from PIL import Image, ImageDraw, ImageFont
import cv2
import numpy as np
from typing import List
import textwrap
import wave

class VideoCreator:
    def __init__(self):
        self.width = 1080  # 9:16 aspect ratio
        self.height = 1920
        self.fps = 30
        
        # C·∫•u h√¨nh Google AI Gemini Client
        self.gemini_api_key = "AIzaSyAcLoIS03oTfbMmblWt0FiyEciszIFrFac"
        self.client = genai.Client(api_key=self.gemini_api_key)
        
        # ƒê∆∞·ªùng d·∫´n ·∫£nh m·∫∑c ƒë·ªãnh
        self.default_images = [
            "default_images/default1.jpg",
            "default_images/default2.jpg"
        ]
        
        # ƒê∆∞·ªùng d·∫´n ·∫£nh outro
        self.outro_images = [
            "default_images/default3.jpg",  # Thanks for Watching
            "default_images/default4.jpg"   # Subscribe & Like
        ]
        
        # 30 gi·ªçng n√≥i Gemini TTS c√≥ s·∫µn
        self.gemini_voices = {
            'Zephyr': 'Zephyr - T∆∞∆°i s√°ng',
            'Puck': 'Puck - R·ªôn r√†ng', 
            'Charon': 'Charon - Cung c·∫•p nhi·ªÅu th√¥ng tin',
            'Kore': 'Kore - Firm',
            'Fenrir': 'Fenrir - D·ªÖ k√≠ch ƒë·ªông',
            'Leda': 'Leda - Tr·∫ª trung',
            'Orus': 'Orus - Firm',
            'Aoede': 'Aoede - Breezy',
            'Callirrhoe': 'Callirrhoe - D·ªÖ ch·ªãu',
            'Autonoe': 'Autonoe - T∆∞∆°i s√°ng',
            'Enceladus': 'Enceladus - Breathy',
            'Iapetus': 'Iapetus - R√µ r√†ng',
            'Umbriel': 'Umbriel - D·ªÖ t√≠nh',
            'Algieba': 'Algieba - L√†m m·ªãn',
            'Despina': 'Despina - Smooth',
            'Erinome': 'Erinome - Clear',
            'Algenib': 'Algenib - Kh√†n',
            'Rasalgethi': 'Rasalgethi - Cung c·∫•p nhi·ªÅu th√¥ng tin',
            'Laomedeia': 'Laomedeia - R·ªôn r√†ng',
            'Achernar': 'Achernar - M·ªÅm',
            'Alnilam': 'Alnilam - Firm',
            'Schedar': 'Schedar - Even',
            'Gacrux': 'Gacrux - Ng∆∞·ªùi tr∆∞·ªüng th√†nh',
            'Pulcherrima': 'Pulcherrima - L·∫°c quan',
            'Achird': 'Achird - Th√¢n thi·ªán',
            'Zubenelgenubi': 'Zubenelgenubi - B√¨nh th∆∞·ªùng',
            'Vindemiatrix': 'Vindemiatrix - √äm d·ªãu',
            'Sadachbia': 'Sadachbia - Lively',
            'Sadaltager': 'Sadaltager - Hi·ªÉu bi·∫øt',
            'Sulafat': 'Sulafat - ·∫§m'
        }
        
    def wave_file(self, filename: str, pcm: bytes, channels: int = 1, rate: int = 24000, sample_width: int = 2):
        """T·∫°o file WAV t·ª´ d·ªØ li·ªáu PCM"""
        with wave.open(filename, "wb") as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(rate)
            wf.writeframes(pcm)
    
    def text_to_speech(self, text: str, output_path: str, voice_name: str = 'Puck'):
        """Chuy·ªÉn text th√†nh √¢m thanh b·∫±ng Gemini TTS API"""
        try:
            # G·ªçi Gemini TTS API
            response = self.client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name=voice_name,
                            )
                        )
                    ),
                )
            )
            
            # L·∫•y d·ªØ li·ªáu √¢m thanh
            data = response.candidates[0].content.parts[0].inline_data.data
            
            # L∆∞u th√†nh file WAV
            self.wave_file(output_path, data)
            
            print(f"‚úÖ Gemini TTS th√†nh c√¥ng v·ªõi gi·ªçng: {voice_name}")
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói Gemini TTS: {str(e)}")
            raise Exception(f"Kh√¥ng th·ªÉ t·∫£o audio v·ªõi Gemini TTS: {str(e)}")
    
    def create_text_image(self, text: str, width: int, height: int, font_size: int = 80):
        """T·∫°o h√¨nh ·∫£nh v·ªõi text ƒë·ªÉ l√†m subtitle - font v·ª´a v√† m√†u ƒë·ªè"""
        img = Image.new('RGBA', (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        try:
            # Th·ª≠ t√¨m font h·ªá th·ªëng cho Windows
            import platform
            if platform.system() == 'Windows':
                try:
                    # Th·ª≠ c√°c font ti·∫øng Vi·ªát ph·ªï bi·∫øn tr√™n Windows
                    font = ImageFont.truetype('arial.ttf', font_size)
                except:
                    try:
                        font = ImageFont.truetype('C:/Windows/Fonts/arial.ttf', font_size)
                    except:
                        try:
                            font = ImageFont.truetype('C:/Windows/Fonts/calibri.ttf', font_size) 
                        except:
                            font = ImageFont.load_default()
            else:
                font = ImageFont.load_default()
        except:
            font = ImageFont.load_default()
        
        # T√≠nh to√°n s·ªë k√Ω t·ª± t·ªëi ƒëa m·ªói d√≤ng d·ª±a tr√™n chi·ªÅu r·ªông v√† font size
        # ƒê·ªÉ l·∫°i margin 40px m·ªói b√™n ƒë·ªÉ tr√°nh tr√†n
        available_width = width - 80  # 40px margin m·ªói b√™n
        approx_char_width = font_size * 0.6  # T·ª∑ l·ªá x·∫•p x·ªâ cho ch·ªØ ti·∫øng Vi·ªát
        max_chars_per_line = int(available_width / approx_char_width)
        max_chars_per_line = max(15, min(max_chars_per_line, 25))  # Gi·ªõi h·∫°n 15-25 k√Ω t·ª±
        
        lines = textwrap.wrap(text, width=max_chars_per_line)
        
        # T√≠nh v·ªã tr√≠ ƒë·ªÉ cƒÉn gi·ªØa text
        line_height = font_size + 10  # Kho·∫£ng c√°ch gi·ªØa c√°c d√≤ng
        total_height = len(lines) * line_height
        start_y = (height - total_height) // 2
        
        for i, line in enumerate(lines):
            # T√≠nh k√≠ch th∆∞·ªõc text
            try:
                bbox = draw.textbbox((0, 0), line, font=font)
                text_width = bbox[2] - bbox[0]
            except:
                # Fallback n·∫øu textbbox kh√¥ng ho·∫°t ƒë·ªông
                text_width = len(line) * (font_size * 0.6)
            
            # ƒê·∫£m b·∫£o text n·∫±m trong gi·ªõi h·∫°n an to√†n (margin 40px)
            x = max(40, min((width - text_width) // 2, width - text_width - 40))
            y = start_y + i * line_height
            
            # V·∫Ω outline ƒëen v·ª´a ph·∫£i
            outline_width = 3
            for dx in range(-outline_width, outline_width+1):
                for dy in range(-outline_width, outline_width+1):
                    if dx != 0 or dy != 0:  # Kh√¥ng v·∫Ω ·ªü t√¢m
                        draw.text((x+dx, y+dy), line, font=font, fill='black')
            
            # V·∫Ω text ch√≠nh m√†u ƒë·ªè
            draw.text((x, y), line, font=font, fill='red')
        
        return img
    
    def resize_image_to_fit(self, image_path: str, target_width: int, target_height: int):
        """Resize h√¨nh ·∫£nh ƒë·ªÉ fit v√†o khung video 9:16"""
        img = Image.open(image_path)
        img = img.convert('RGB')
        
        # T√≠nh t·ª∑ l·ªá ƒë·ªÉ fit v√†o khung
        img_ratio = img.width / img.height
        target_ratio = target_width / target_height
        
        if img_ratio > target_ratio:
            # ·∫¢nh r·ªông h∆°n, c·∫Øt theo chi·ªÅu r·ªông
            new_height = target_height
            new_width = int(new_height * img_ratio)
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # C·∫Øt ph·∫ßn th·ª´a
            left = (new_width - target_width) // 2
            img = img.crop((left, 0, left + target_width, target_height))
        else:
            # ·∫¢nh cao h∆°n, c·∫Øt theo chi·ªÅu cao
            new_width = target_width
            new_height = int(new_width / img_ratio)
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            
            # C·∫Øt ph·∫ßn th·ª´a
            top = (new_height - target_height) // 2
            img = img.crop((0, top, target_width, top + target_height))
        
        return img
    
    def create_video(self, text: str, image_paths: List[str], output_filename: str, voice_name: str = 'Puck'):
        """T·∫°o video t·ª´ text v√† h√¨nh ·∫£nh"""
        try:
            # T·∫°o file √¢m thanh
            audio_path = f"temp_audio_{uuid.uuid4().hex}.mp3"
            if not self.text_to_speech(text, audio_path, voice_name):
                return False, "L·ªói t·∫°o √¢m thanh"
            
            # Load √¢m thanh ƒë·ªÉ l·∫•y th·ªùi l∆∞·ª£ng
            audio_clip = AudioFileClip(audio_path)
            duration = audio_clip.duration
            
            # T·∫°o video clips t·ª´ h√¨nh ·∫£nh
            video_clips = []
            
            # N·∫øu kh√¥ng c√≥ h√¨nh ·∫£nh upload, s·ª≠ d·ª•ng ·∫£nh m·∫∑c ƒë·ªãnh
            if not image_paths:
                image_paths = self.default_images.copy()
                print(f"üñºÔ∏è S·ª≠ d·ª•ng {len(image_paths)} ·∫£nh m·∫∑c ƒë·ªãnh")
            
            # Chia th·ªùi gian cho m·ªói h√¨nh ·∫£nh
            time_per_image = duration / len(image_paths)
            
            for i, image_path in enumerate(image_paths):
                try:
                    # Resize h√¨nh ·∫£nh
                    resized_img = self.resize_image_to_fit(image_path, self.width, self.height)
                    
                    # L∆∞u h√¨nh ·∫£nh t·∫°m
                    temp_img_path = f"temp_img_{i}_{uuid.uuid4().hex}.jpg"
                    resized_img.save(temp_img_path)
                    
                    # T·∫°o clip t·ª´ h√¨nh ·∫£nh
                    img_clip = ImageClip(temp_img_path, duration=time_per_image)
                    video_clips.append(img_clip)
                    
                    # X√≥a file t·∫°m
                    os.remove(temp_img_path)
                    
                except Exception as e:
                    print(f"Error processing image {image_path}: {e}")
                    # N·∫øu l·ªói, s·ª≠ d·ª•ng background ƒëen
                    backup_clip = ColorClip(size=(self.width, self.height), color=(0, 0, 0), duration=time_per_image)
                    video_clips.append(backup_clip)
            
            # Th√™m outro v√†o cu·ªëi video
            outro_duration = 3.0  # 3 gi√¢y
            outro_image = random.choice(self.outro_images)  # Ch·ªçn ng·∫´u nhi√™n
            print(f"üé¨ Th√™m outro: {outro_image.split('/')[-1]}")
            
            try:
                # T·∫°o clip outro
                outro_resized = self.resize_image_to_fit(outro_image, self.width, self.height)
                outro_temp_path = f"temp_outro_{uuid.uuid4().hex}.jpg"
                outro_resized.save(outro_temp_path)
                outro_clip = ImageClip(outro_temp_path, duration=outro_duration)
                video_clips.append(outro_clip)
                os.remove(outro_temp_path)
            except Exception as e:
                print(f"L·ªói t·∫°o outro: {e}")
                # Fallback: outro ƒëen
                outro_clip = ColorClip(size=(self.width, self.height), color=(0, 0, 0), duration=outro_duration)
                video_clips.append(outro_clip)
            
            # Gh√©p c√°c clip l·∫°i (bao g·ªìm outro)
            if video_clips:
                final_video = concatenate_videoclips(video_clips)
            else:
                # Fallback n·∫øu t·∫•t c·∫£ ·∫£nh ƒë·ªÅu l·ªói
                final_video = ColorClip(size=(self.width, self.height), color=(0, 0, 0), duration=duration + outro_duration)
            
            # T·∫°o subtitle (ch·ªâ hi·ªÉn th·ªã trong th·ªùi gian audio, kh√¥ng c√≥ trong outro)
            words = text.split()
            subtitle_clips = []
            words_per_second = len(words) / duration
            
            # Chia text th√†nh c√°c ƒëo·∫°n ng·∫Øn
            chunk_size = max(1, int(words_per_second * 2))  # 2 gi√¢y m·ªói ƒëo·∫°n
            
            for i in range(0, len(words), chunk_size):
                chunk_words = words[i:i+chunk_size]
                chunk_text = " ".join(chunk_words)
                
                start_time = i / words_per_second
                end_time = min((i + chunk_size) / words_per_second, duration)
                
                # Ch·ªâ hi·ªÉn th·ªã subtitle trong th·ªùi gian audio
                if start_time >= duration:
                    break
                    
                # T·∫°o h√¨nh ·∫£nh text - v√πng subtitle v·ª´a ƒë·ªß
                text_img = self.create_text_image(chunk_text, self.width, 200)
                text_img_path = f"temp_text_{i}_{uuid.uuid4().hex}.png"
                text_img.save(text_img_path)
                
                # T·∫°o clip subtitle v·ªõi v·ªã tr√≠ bottom v√† margin 20px
                txt_clip = ImageClip(text_img_path, duration=end_time-start_time).with_start(start_time).with_position(('center', self.height - 420))
                subtitle_clips.append(txt_clip)
                
                # X√≥a file t·∫°m
                os.remove(text_img_path)
            
            # K·∫øt h·ª£p video v·ªõi subtitle
            if subtitle_clips:
                final_video = CompositeVideoClip([final_video] + subtitle_clips)
            
            # Th√™m √¢m thanh (ch·ªâ ph√°t trong th·ªùi gian n·ªôi dung ch√≠nh, outro kh√¥ng c√≥ √¢m thanh)
            # √Çm thanh s·∫Ω t·ª± ƒë·ªông d·ª´ng ·ªü th·ªùi ƒëi·ªÉm k·∫øt th√∫c c·ªßa audio_clip
            final_video = final_video.with_audio(audio_clip)
            
            # Xu·∫•t video
            output_path = f"outputs/{output_filename}"
            final_video.write_videofile(
                output_path, 
                fps=self.fps, 
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            # D·ªçn d·∫πp
            audio_clip.close()
            final_video.close()
            os.remove(audio_path)
            
            return True, output_path
            
        except Exception as e:
            print(f"Error creating video: {e}")
            return False, str(e)